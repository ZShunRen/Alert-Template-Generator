ARG CUDA_IMAGE="12.5.0-devel-ubuntu22.04"
FROM nvidia/cuda:${CUDA_IMAGE}

RUN mkdir -p /app/server

WORKDIR /app/server

# We need to set the host to 0.0.0.0 to allow outside access
ENV HOST 0.0.0.0
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \ 
    python3 \
    python3-pip \
    python3-venv \ 
    gcc \
    wget \
    ocl-icd-opencl-dev \
    opencl-headers \
    clinfo \
    libclblast-dev \
    libopenblas-dev \
    && mkdir -p /etc/OpenCL/vendors && echo "libnvidia-opencl.so.1" > /etc/OpenCL/vendors/nvidia.icd

COPY requirements.txt .

RUN python3 -m venv venv \
    && . venv/bin/activate \
    && pip install -r requirements.txt

COPY . .

# setting build related env vars
ENV CUDA_DOCKER_ARCH=all
ENV LLAMA_CUBLAS=1

# Install llama-cpp-python (build with cuda)
RUN . venv/bin/activate && CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE="1" pip install llama-cpp-python==0.2.79 --upgrade --force-reinstall --no-cache-dir

EXPOSE 5000

# Run the server
CMD ["/bin/sh", "-c", ". /app/server/venv/bin/activate && python3 api_llm.py"]